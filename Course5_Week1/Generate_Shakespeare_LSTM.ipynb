{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "- Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(text, T_x=40, stride=3):\n",
    "    '''\n",
    "    Create a training data by scanning a window of size T_x over the text corpus, with stride 3.\n",
    "    \n",
    "    Arguments:\n",
    "    text   -- string, corpus of Shakespearian poem\n",
    "    T_x    -- integer, number of time-steps (or characters) in one training example\n",
    "    stride -- integer, how much the window shift itself while scanning\n",
    "    \n",
    "    Returns:\n",
    "    X      -- list of training examples\n",
    "    Y      -- list of training labels\n",
    "    '''\n",
    "    \n",
    "    # Initialize\n",
    "    X, Y = [], []\n",
    "    \n",
    "    # Loop\n",
    "    for i in range(0, len(text)-T_x, stride):\n",
    "        X.append(text[i: (i+T_x)])\n",
    "        Y.append(text[i+T_x])\n",
    "    \n",
    "    print('number of raw training examples: ', len(X))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(X, Y, n_x, char_to_idx, T_x=40):\n",
    "    '''\n",
    "    Convert X and Y (lists) into arrays to be fed into RNN.\n",
    "    \n",
    "    Returns:\n",
    "    x      -- array of shape (m, T_x, n_x)\n",
    "    y      -- array of shape (m, n_x)\n",
    "    '''\n",
    "    \n",
    "    m = len(X)\n",
    "    x = np.zeros((m, T_x, n_x), dtype=np.bool)\n",
    "    y = np.zeros((m, n_x), dtype=np.bool)\n",
    "    \n",
    "    for i, sentence in enumerate(X):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_to_idx[char]] = 1\n",
    "        y[i, char_to_idx[Y[i]]] = 1\n",
    "    \n",
    "    print('x.shape = ', x.shape)\n",
    "    print('y.shape = ', y.shape)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(preds, temperature=1.0):\n",
    "    \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds - np.max(preds))\n",
    "    probas = exp_preds / exp_preds.sum(axis=0)\n",
    "    out = np.random.choice(range(len(chars)), p=probas.ravel())\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(model):\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    usr_input = input('Input the beginning of your poem: ')\n",
    "    \n",
    "    sentence = ('{0:0>' + str(T_x) + '}').format(usr_input).lower()\n",
    "    generated += usr_input\n",
    "    \n",
    "    sys.stdout.write('\\n\\nHere is your poem: \\n\\n')\n",
    "    sys.stdout.write(usr_input)\n",
    "    for i in range(400):\n",
    "        \n",
    "        x_pred = np.zeros((1, T_x, len(chars)))\n",
    "        \n",
    "        for t, char in enumerate(sentence):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_to_idx[char]] = 1\n",
    "                \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_idx = sampling(preds)\n",
    "        next_char = idx_to_char[next_idx]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if next_char == '\\n':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 94275 | Corpus length: 38\n"
     ]
    }
   ],
   "source": [
    "text = open('shakespeare.txt', 'r').read().lower()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "text_size, corpus_size = len(text), len(chars)\n",
    "print('Text length: %d | Corpus length: %d' %  (text_size, corpus_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtable mapping characters to the indices\n",
    "char_to_idx = {char:i for i,char in enumerate(chars)}\n",
    "\n",
    "# hashtable mapping indices to characters\n",
    "idx_to_char = {i:char for i, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of raw training examples:  31412\n",
      "x.shape =  (31412, 40, 38)\n",
      "y.shape =  (31412, 38)\n"
     ]
    }
   ],
   "source": [
    "# Set time-step\n",
    "T_x = 40\n",
    "\n",
    "# Raw training set\n",
    "X, Y = generate_training_data(text, T_x, stride=3)\n",
    "\n",
    "# Vectorizing training set\n",
    "x, y = vectorization(X, Y, n_x=corpus_size, char_to_idx=char_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = np.random.randint(0, len(text) - T_x - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + T_x]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, T_x, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_to_idx[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sampling(preds, diversity)\n",
    "            next_char = idx_to_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(units=128, input_shape=(T_x, corpus_size)))\n",
    "model.add(tf.keras.layers.Dense(corpus_size, activation='softmax'))\n",
    "\n",
    "# set RMSprop optimizer\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# set callback\n",
    "print_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# training\n",
    "model.fit(x, y, batch_size=128, epochs=60, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denn1s/miniconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_load = tf.keras.models.load_model('model_shakespeare_kiank_350_epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31412/31412 [==============================] - 20s 639us/sample - loss: 2.5657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6facbc5e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_callback = tf.keras.callbacks.LambdaCallback()\n",
    "\n",
    "model_load.fit(x, y, batch_size=128, epochs=1, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the beginning of your poem: Forsooth this maketh no sense \n",
      "\n",
      "\n",
      "Here is your poem: \n",
      "\n",
      "Forsooth this maketh no sense but work,\n",
      "and cruece not besite thou brace othing,\n",
      "pant is that in buss so boy what seorts\n",
      "whon the dears deseow it that hadn behind,\n",
      "on tay somere kifs wising the bardth othib save,\n",
      "ad, bligis thy dost, yet bewigh dieds,\n",
      "and in sain to well shake you aro lays,\n",
      "then my sich fortore meriroh her o'anteress,\n",
      "whatie pain the indient my doth and hadist love,\n",
      "so de paeray asaluss leog resaty and,\n",
      "cosy s"
     ]
    }
   ],
   "source": [
    "generate_output(model_load)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
